{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchdata==0.3.0 in /root/.local/lib/python3.7/site-packages (0.3.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /opt/conda/lib/python3.7/site-packages (from torchdata==0.3.0) (1.11.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.7/site-packages (from torchdata==0.3.0) (1.25.7)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchdata==0.3.0) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.11.0->torchdata==0.3.0) (3.7.4.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchdata==0.3.0) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchdata==0.3.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchdata==0.3.0) (2019.11.28)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchdata==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eg81uNTWixbi",
    "outputId": "9c0f9eda-75fb-4526-e9b6-f9a76eeeb007"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import itertools\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import time\n",
    "\n",
    "from nltk.corpus import brown\n",
    "# import dataset SQuAD2 as suggsted\n",
    "from torchtext.datasets import SQuAD2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Output, save, and load brown embeddings\n",
    "# model = gensim.models.Word2Vec(brown.sents())\n",
    "# model.save('brown.embedding')\n",
    "# w2v = gensim.models.Word2Vec.load('brown.embedding')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You will use this function to load the dataset into a Pandas Dataframe for processing.\n",
    "def loadDF(ds):\n",
    "    df = {\"question\": [], \"answer\": []}\n",
    "    for context, question, answers, indices in ds:\n",
    "        if answers[0]:\n",
    "            df[\"question\"].append(question)\n",
    "            df[\"answer\"].append(answers[0])\n",
    "    return pd.DataFrame.from_dict(df)\n",
    "    \n",
    "\n",
    "def prepare_text(sentence):\n",
    "    '''\n",
    "    Our text needs to be cleaned with a tokenizer. This function will perform that task.\n",
    "    https://www.nltk.org/api/nltk.tokenize.html\n",
    "    '''\n",
    "    return nltk.tokenize.word_tokenize(sentence)\n",
    "\n",
    "\n",
    "def train_test_split(SRC, TRG):\n",
    "    '''\n",
    "    Input: SRC, our list of questions from the dataset\n",
    "           TRG, our list of responses from the dataset\n",
    "    Output: Training and test datasets for SRC & TRG\n",
    "    '''\n",
    "    \n",
    "    SRC_train_dataset = train_df[\"question\"].tolist()\n",
    "    TRG_train_dataset = train_df[\"answer\"].tolist()\n",
    "    \n",
    "    SRC_test_dataset = test_df[\"question\"].tolist()\n",
    "    TRG_test_dataset = test_df[\"answer\"].tolist()\n",
    "        \n",
    "    return SRC_train_dataset, SRC_test_dataset, TRG_train_dataset, TRG_test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = SQuAD2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = loadDF(train_dataset)\n",
    "test_df = loadDF(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question               answer\n",
       "0           When did Beyonce start becoming popular?    in the late 1990s\n",
       "1  What areas did Beyonce compete in when she was...  singing and dancing\n",
       "2  When did Beyonce leave Destiny's Child and bec...                 2003\n",
       "3      In what city and state did Beyonce  grow up?        Houston, Texas\n",
       "4         In which decade did Beyonce become famous?           late 1990s"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 86821 sentence pairs\n"
     ]
    }
   ],
   "source": [
    "import util as util\n",
    "print(\"Start preparing training data ...\")\n",
    "voc, pairs = util.readVocs(train_df, \"train\")\n",
    "print(\"Read {!s} sentence pairs\".format(len(pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed to 29334 sentence pairs\n"
     ]
    }
   ],
   "source": [
    "pairs = util.filterPairs(pairs)\n",
    "print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting words...\n",
      "Counted words: 28298\n"
     ]
    }
   ],
   "source": [
    "print(\"Counting words...\")\n",
    "for pair in pairs:\n",
    "    voc.addSentence(pair[0])\n",
    "    voc.addSentence(pair[1])\n",
    "print(\"Counted words:\", voc.num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when did beyonce start becoming popular ?', 'in the late s']\n",
      "['in which decade did beyonce become famous ?', 'late s']\n",
      "['what album made her a worldwide known artist ?', 'dangerously in love']\n",
      "['who managed the destiny s child group ?', 'mathew knowles']\n",
      "['when did beyonce rise to fame ?', 'late s']\n"
     ]
    }
   ],
   "source": [
    "for pair in pairs[:5]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 9536 / 28295 = 0.3370\n",
      "Trimmed from 29334 pairs to 13802, 0.4705 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'addSentence', 'addWord', 'index2word', 'name', 'num_words', 'trim', 'trimmed', 'word2count', 'word2index']\n"
     ]
    }
   ],
   "source": [
    "print(dir(voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9539"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "MAX_LENGTH = 10 # Maximun Length of the statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[  18,   48,   18,    3,   60],\n",
      "        [1505,   55,    4,    4,  297],\n",
      "        [  41, 8051,   11,   11,  939],\n",
      "        [  42,  341,  188, 9352,  823],\n",
      "        [3434,   10, 1211,  937,    6],\n",
      "        [ 164,   11, 1759, 1642,    9],\n",
      "        [ 627, 9536,  697,    9,    2],\n",
      "        [4534,  678,    9,    2,    0],\n",
      "        [   9,    9,    2,    0,    0],\n",
      "        [   2,    2,    0,    0,    0]])\n",
      "lengths: tensor([10, 10,  9,  8,  7])\n",
      "target_variable: tensor([[ 842,  631,   22, 3347,   42],\n",
      "        [1024,    2, 1760,    2, 2111],\n",
      "        [   2,    0, 1761,    0,    2],\n",
      "        [   0,    0,  397,    0,    0],\n",
      "        [   0,    0,  212,    0,    0],\n",
      "        [   0,    0, 1762,    0,    0],\n",
      "        [   0,    0,  917,    0,    0],\n",
      "        [   0,    0, 1073,    0,    0],\n",
      "        [   0,    0, 1182,    0,    0],\n",
      "        [   0,    0,    2,    0,    0]])\n",
      "mask: tensor([[ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True, False,  True, False,  True],\n",
      "        [False, False,  True, False, False],\n",
      "        [False, False,  True, False, False],\n",
      "        [False, False,  True, False, False],\n",
      "        [False, False,  True, False, False],\n",
      "        [False, False,  True, False, False],\n",
      "        [False, False,  True, False, False],\n",
      "        [False, False,  True, False, False]])\n",
      "max_target_len: 10\n"
     ]
    }
   ],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.BoolTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder, Decoder and Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "9539\n"
     ]
    }
   ],
   "source": [
    "print(len(input_variable))\n",
    "print(len(target_variable))\n",
    "print(voc.num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjustable parameters\n",
    "INPUT_DIM = voc.num_words\n",
    "OUTPUT_DIM = voc.num_words\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, emb_dim: int, hid_dim: int, n_layers: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "\n",
    "    def forward(self, src_batch: torch.LongTensor):\n",
    "        embedded = self.embedding(src_batch) # [sent len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # outputs -> [sent len, batch size, hidden dim * n directions]\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 512]), torch.Size([2, 5, 512]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
    "hidden, cell = encoder(input_variable)\n",
    "hidden.shape, cell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim: int, emb_dim: int, hid_dim: int, n_layers: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, trg: torch.LongTensor, hidden: torch.FloatTensor, cell: torch.FloatTensor):\n",
    "        # [1, batch size, emb dim], the 1 serves as sent len\n",
    "        embedded = self.embedding(trg.unsqueeze(0))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.out(outputs.squeeze(0))\n",
    "        return prediction, hidden, cell\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 9539]), torch.Size([2, 5, 512]), torch.Size([2, 5, 512]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT).to(device)\n",
    "\n",
    "# notice that we are not passing the entire the .trg\n",
    "prediction, hidden, cell = decoder(input_variable[0], hidden, cell)\n",
    "prediction.shape, hidden.shape, cell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            'Hidden dimensions of encoder and decoder must be equal!'\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            'Encoder and decoder must have equal number of layers!'\n",
    "\n",
    "    def forward(self, src_batch: torch.LongTensor, trg_batch: torch.LongTensor,\n",
    "                teacher_forcing_ratio: float=0.5):\n",
    "\n",
    "        max_len, batch_size = trg_batch.shape\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # tensor to store decoder's output\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        # last hidden & cell state of the encoder is used as the decoder's initial hidden state\n",
    "        hidden, cell = self.encoder(src_batch)\n",
    "\n",
    "        trg = trg_batch[0]\n",
    "        for i in range(1, max_len):\n",
    "            prediction, hidden, cell = self.decoder(trg, hidden, cell)\n",
    "            outputs[i] = prediction\n",
    "\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                trg = trg_batch[i]\n",
    "            else:\n",
    "                trg = prediction.argmax(1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(9539, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(9539, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (out): Linear(in_features=512, out_features=9539, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that this implementation assumes that the size of the hidden layer,\n",
    "# and the number of layer are the same between the encoder and decoder\n",
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "seq2seq = Seq2Seq(encoder, decoder, device).to(device)\n",
    "seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 9539])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = seq2seq(input_variable, target_variable)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 17,133,891 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(seq2seq):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the optimizer and criterion\n",
    "optimizer = optim.Adam(seq2seq.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(seq2seq, training_batch, optimizer, criterion):\n",
    "    seq2seq.train()\n",
    "     # Extract fields from batch\n",
    "    input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "    print(\"Training...\")\n",
    "    epoch_loss = 0\n",
    "    for batch in training_batch:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = seq2seq(training_batch[0], training_batch[2])\n",
    "\n",
    "        # 1. as mentioned in the seq2seq section, we will\n",
    "        # cut off the first element when performing the evaluation\n",
    "        # 2. the loss function only works on 2d inputs\n",
    "        # with 1d targets we need to flatten each of them\n",
    "        outputs_flatten = outputs[1:].view(-1, outputs.shape[-1])\n",
    "        trg_flatten = training_batch[2][1:].view(-1)\n",
    "        loss = criterion(outputs_flatten, trg_flatten)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(training_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(seq2seq, training_batch, criterion):\n",
    "    seq2seq.eval()\n",
    "    print(\"Evaluating...\")\n",
    "    input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in training_batch:\n",
    "            # turn off teacher forcing\n",
    "            outputs = seq2seq(training_batch[0], training_batch[2], teacher_forcing_ratio=0) \n",
    "\n",
    "            # trg = [trg sent len, batch size]\n",
    "            # output = [trg sent len, batch size, output dim]\n",
    "            outputs_flatten = outputs[1:].view(-1, outputs.shape[-1])\n",
    "            trg_flatten = training_batch[2][1:].view(-1)\n",
    "            loss = criterion(outputs_flatten, trg_flatten)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(training_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training batches100\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 01 | Time: 0m 16s\n",
      "\tTrain Loss: 6.812 | Train PPL: 908.350\n",
      "\t Val. Loss: 2.301 |  Val. PPL:   9.985\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 02 | Time: 0m 15s\n",
      "\tTrain Loss: 2.165 | Train PPL:   8.715\n",
      "\t Val. Loss: 1.559 |  Val. PPL:   4.754\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 03 | Time: 0m 15s\n",
      "\tTrain Loss: 1.736 | Train PPL:   5.677\n",
      "\t Val. Loss: 1.534 |  Val. PPL:   4.636\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 04 | Time: 0m 15s\n",
      "\tTrain Loss: 1.953 | Train PPL:   7.048\n",
      "\t Val. Loss: 1.784 |  Val. PPL:   5.953\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 05 | Time: 0m 15s\n",
      "\tTrain Loss: 1.794 | Train PPL:   6.012\n",
      "\t Val. Loss: 1.658 |  Val. PPL:   5.249\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 06 | Time: 0m 15s\n",
      "\tTrain Loss: 1.674 | Train PPL:   5.332\n",
      "\t Val. Loss: 1.561 |  Val. PPL:   4.765\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 07 | Time: 0m 15s\n",
      "\tTrain Loss: 1.484 | Train PPL:   4.409\n",
      "\t Val. Loss: 1.410 |  Val. PPL:   4.095\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 08 | Time: 0m 15s\n",
      "\tTrain Loss: 1.476 | Train PPL:   4.376\n",
      "\t Val. Loss: 1.444 |  Val. PPL:   4.236\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 09 | Time: 0m 13s\n",
      "\tTrain Loss: 1.591 | Train PPL:   4.907\n",
      "\t Val. Loss: 1.535 |  Val. PPL:   4.642\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 10 | Time: 0m 13s\n",
      "\tTrain Loss: 1.731 | Train PPL:   5.645\n",
      "\t Val. Loss: 1.818 |  Val. PPL:   6.160\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 11 | Time: 0m 15s\n",
      "\tTrain Loss: 1.496 | Train PPL:   4.463\n",
      "\t Val. Loss: 1.603 |  Val. PPL:   4.969\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 12 | Time: 0m 15s\n",
      "\tTrain Loss: 1.234 | Train PPL:   3.436\n",
      "\t Val. Loss: 1.265 |  Val. PPL:   3.542\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 13 | Time: 0m 15s\n",
      "\tTrain Loss: 1.438 | Train PPL:   4.211\n",
      "\t Val. Loss: 1.464 |  Val. PPL:   4.322\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 14 | Time: 0m 12s\n",
      "\tTrain Loss: 1.627 | Train PPL:   5.089\n",
      "\t Val. Loss: 1.691 |  Val. PPL:   5.422\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 15 | Time: 0m 14s\n",
      "\tTrain Loss: 1.368 | Train PPL:   3.929\n",
      "\t Val. Loss: 1.408 |  Val. PPL:   4.087\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 16 | Time: 0m 13s\n",
      "\tTrain Loss: 1.754 | Train PPL:   5.776\n",
      "\t Val. Loss: 1.919 |  Val. PPL:   6.812\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 17 | Time: 0m 14s\n",
      "\tTrain Loss: 1.666 | Train PPL:   5.293\n",
      "\t Val. Loss: 1.692 |  Val. PPL:   5.431\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 18 | Time: 0m 14s\n",
      "\tTrain Loss: 1.447 | Train PPL:   4.249\n",
      "\t Val. Loss: 1.675 |  Val. PPL:   5.339\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 19 | Time: 0m 13s\n",
      "\tTrain Loss: 1.995 | Train PPL:   7.352\n",
      "\t Val. Loss: 2.092 |  Val. PPL:   8.103\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 20 | Time: 0m 15s\n",
      "\tTrain Loss: 1.648 | Train PPL:   5.196\n",
      "\t Val. Loss: 1.829 |  Val. PPL:   6.229\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# Load batches for each iteration\n",
    "training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(128)]) for _ in range(100)]\n",
    "print(\"Length of training batches\"+str(len(training_batches)))\n",
    "\n",
    "for epoch in range(N_EPOCHS): \n",
    "    training_batch = training_batches[epoch - 1]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss = train(seq2seq, training_batch, optimizer, criterion)\n",
    "    valid_loss = evaluate(seq2seq, training_batch, criterion)\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(seq2seq.state_dict(), 'chatbotmodel.pt')\n",
    "\n",
    "    # it's easier to see a change in perplexity between epoch as it's an exponential\n",
    "    # of the loss, hence the scale of the measure is much bigger\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing testing data ...\n",
      "Reading lines...\n",
      "Read 5928 sentence pairs\n",
      "Trimmed to 1761 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 4434\n",
      "['in what country is normandy located ?', 'france']\n",
      "['when were the normans in normandy ?', 'th and th centuries']\n",
      "['from which countries did the norse originate ?', 'denmark iceland and norway']\n",
      "['who was the norse leader ?', 'rollo']\n",
      "['who ruled the duchy of normandy', 'richard i']\n",
      "keep_words 1022 / 4431 = 0.2306\n",
      "Trimmed from 1761 pairs to 177, 0.1005 of total\n",
      "1025\n"
     ]
    }
   ],
   "source": [
    "print(\"Start preparing testing data ...\")\n",
    "voc, test_pairs = util.readVocs(test_df, \"test\")\n",
    "print(\"Read {!s} sentence pairs\".format(len(test_pairs)))\n",
    "\n",
    "test_pairs = util.filterPairs(test_pairs)\n",
    "print(\"Trimmed to {!s} sentence pairs\".format(len(test_pairs)))\n",
    "\n",
    "print(\"Counting words...\")\n",
    "for test_pair in test_pairs:\n",
    "    voc.addSentence(test_pair[0])\n",
    "    voc.addSentence(test_pair[1])\n",
    "print(\"Counted words:\", voc.num_words)\n",
    "\n",
    "for test_pair in test_pairs[:5]:\n",
    "    print(test_pair)\n",
    "\n",
    "# Trim voc and pairs\n",
    "test_pairs = trimRareWords(voc, test_pairs, MIN_COUNT)\n",
    "\n",
    "print(voc.num_words)\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "test_batches = batch2TrainData(voc, [random.choice(test_pairs) for _ in range(small_batch_size)])\n",
    "test_input_variable, lengths, test_target_variable, mask, max_target_len = test_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "| Test Loss: 3.450 | Test PPL:  31.505 |\n"
     ]
    }
   ],
   "source": [
    "seq2seq.load_state_dict(torch.load('chatbotmodel.pt'))\n",
    "\n",
    "test_loss = evaluate(seq2seq, test_batches, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 5, 9539])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = seq2seq(test_input_variable, test_target_variable, teacher_forcing_ratio=0)\n",
    "\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n"
     ]
    }
   ],
   "source": [
    "print(voc.index2word[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denmark iceland and norway\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output_idx = outputs[1:].squeeze(1).argmax(1)\n",
    "    for idx in output_idx:\n",
    "        if not (voc.index2word[idx] == 'EOS' or voc.index2word[idx] == 'PAD'):\n",
    "            ' '.join([voc.index2word[idx]])   \n",
    "except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#End of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special thanks and credits to the mentors for Module-3 LSTM Chatbot \"Akintunde and Osama\"\n",
    "\n",
    "# Courtesy and gratitude for the inspiration by the tutorials, ideas and github links:\n",
    "    #https://pytorch.org/tutorials/beginner/chatbot_tutorial.html\n",
    "    #http://ethen8181.github.io/machine-learning/deep_learning/seq2seq/1_torch_seq2seq_intro.html\n",
    "    #https://github.com/ywk991112/pytorch-chatbot\n",
    "    #https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation-batched.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
